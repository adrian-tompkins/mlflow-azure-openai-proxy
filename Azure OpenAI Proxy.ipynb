{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "945e6bdc-7aee-49c4-aa65-2fe800508731",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Define the Proxy Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39a991e5-0cfb-4ae5-b115-6c157c9e6518",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import mlflow\n",
    "\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "uc_model_location = \"adrian_test.genai.azure_openai_proxy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d46b930c-daf8-446b-9bf7-cdcbd612cead",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import openai\n",
    "import httpx\n",
    "import os\n",
    "import socket\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "class AzureOpenAPIProxy(mlflow.pyfunc.PythonModel):\n",
    "    def __init__(self):\n",
    "        self.override_config = None\n",
    "    \n",
    "    def _get_config_value(self, context, key, default_value=None):\n",
    "        value = context.model_config.get(key)\n",
    "        if value in (None, \"\"):\n",
    "            value = os.getenv(key, default_value)\n",
    "        assert value not in (None, \"\"), f\"Missing value for key {key}\" \n",
    "        return str(value)\n",
    "\n",
    "    @staticmethod\n",
    "    def get_config_properties():\n",
    "        return [\n",
    "            \"AZURE_OPENAI_API_KEY\",\n",
    "            \"AZURE_OPENAI_ENDPOINT\",\n",
    "            \"AZURE_OPENAI_API_VERSION\",\n",
    "            \"AZURE_OPENAI_MODEL\",\n",
    "            \"AZURE_OPENAI_VERIFY_SSL\"\n",
    "        ]\n",
    "\n",
    "    def load_context(self, context):\n",
    "        self.api_key = self._get_config_value(context, \"AZURE_OPENAI_API_KEY\")\n",
    "        self.azure_endpoint = self._get_config_value(context, \"AZURE_OPENAI_ENDPOINT\")\n",
    "        self.api_version = self._get_config_value(context, \"AZURE_OPENAI_API_VERSION\")\n",
    "        self.model = self._get_config_value(context, \"AZURE_OPENAI_MODEL\")\n",
    "        self.verify_ssl = self._get_config_value(context, \"AZURE_OPENAI_VERIFY_SSL\", \"true\")\n",
    "        assert self.verify_ssl in (\"True\", \"true\", \"False\", \"false\"), f\"AZURE_OPENAI_VERIFY_SSL must be either True or False, got {self.verify_ssl}\"\n",
    "        self.verify_ssl = self.verify_ssl in (\"True\", \"true\")\n",
    "        \n",
    "        # Check if this is being resolved privately\n",
    "        domain = urlparse(self.azure_endpoint).netloc\n",
    "        addr1 = socket.gethostbyname_ex(domain)\n",
    "        print(addr1)\n",
    "\n",
    "        self.client = openai.AzureOpenAI(\n",
    "            api_key=self.api_key,  \n",
    "            api_version=self.api_version,\n",
    "            azure_endpoint=self.azure_endpoint,\n",
    "            http_client=httpx.Client(verify=self.verify_ssl)\n",
    "        ) \n",
    "\n",
    "\n",
    "    def predict(self, context, messages, params):\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=\"gpt-4\",\n",
    "            messages=messages.to_dict(orient=\"records\")[0][\"messages\"]\n",
    "        )\n",
    "        return response.dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0602878f-010e-4798-aeff-fdd8e4f86c55",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "conda_env = mlflow.pyfunc.get_default_conda_env()\n",
    "for dep in conda_env[\"dependencies\"]:\n",
    "    if type(dep) == type({}) and \"pip\" in dep: \n",
    "        dep[\"pip\"] += [\n",
    "        f\"openai=={openai.__version__}\"\n",
    "    ]\n",
    "conda_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65ad7f52-7b2a-465c-85d6-a389aff6b11c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=AzureOpenAPIProxy(),\n",
    "        signature=mlflow.models.ModelSignature(\n",
    "                mlflow.types.llm.CHAT_MODEL_INPUT_SCHEMA,\n",
    "                mlflow.types.llm.CHAT_MODEL_OUTPUT_SCHEMA\n",
    "            ),\n",
    "        conda_env=conda_env,\n",
    "        model_config={key:None for key in AzureOpenAPIProxy.get_config_properties()},\n",
    "        registered_model_name=uc_model_location\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f1d8fcc9-72e3-4ed3-aa47-89ca5faeaed0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Test the Proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "016f12e1-ae78-40f1-99e6-9a346148d2d3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow_client = mlflow.MlflowClient()\n",
    "model_versions = mlflow_client.search_model_versions(f\"name='{uc_model_location}'\")\n",
    "max_version = max([mv.version for mv in model_versions])\n",
    "logged_model = f'models:/{uc_model_location}/{max_version}'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model, model_config={\n",
    "    \"AZURE_OPENAI_API_KEY\": dbutils.secrets.get(\"<scope>\", \"<key>\"),\n",
    "    \"AZURE_OPENAI_ENDPOINT\": \"https://<endpoint>.openai.azure.com\",\n",
    "    \"AZURE_OPENAI_API_VERSION\": \"2023-05-15\",\n",
    "    \"AZURE_OPENAI_MODEL\": \"gpt-4\",\n",
    "    \"AZURE_OPENAI_VERIFY_SSL\": \"True\"\n",
    "})\n",
    "\n",
    "response = loaded_model.predict({\"messages\": [{\"role\": \"user\", \"content\": \"Hello, how are you?\"}]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5c41b8b-69d8-4391-a01e-ccf6e16c81fa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dabb5bf-f996-48d9-8712-120559ff010d",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Deploy the Proxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a41553b0-90f3-411e-b441-fe16cacc28b7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from requests.exceptions import HTTPError\n",
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "\n",
    "def create_or_update_depyloyment(name, api_key_secret_scope, api_key_secret_key, api_version, api_endpoint, verify_ssl=\"True\", model=\"gpt-4\"):\n",
    "    deploy_client = get_deploy_client(\"databricks\")\n",
    "    mlflow_client = mlflow.MlflowClient()\n",
    "    model_versions = mlflow_client.search_model_versions(f\"name='{uc_model_location}'\")\n",
    "    max_version = max([mv.version for mv in model_versions])\n",
    "    model_config={\n",
    "        \"served_entities\": [\n",
    "            {\n",
    "                \"entity_name\": uc_model_location,\n",
    "                \"entity_version\": max_version,\n",
    "                \"workload_size\": \"Small\",\n",
    "                \"scale_to_zero_enabled\": True,\n",
    "                'environment_vars': {\n",
    "                    'AZURE_OPENAI_API_KEY': f'{{{{secrets/{api_key_secret_scope}/{api_key_secret_key}}}}}',\n",
    "                    'AZURE_OPENAI_API_VERSION': api_version,\n",
    "                    'AZURE_OPENAI_ENDPOINT': api_endpoint,\n",
    "                    'AZURE_OPENAI_MODEL': model,\n",
    "                    'AZURE_OPENAI_VERIFY_SSL': verify_ssl\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "        \"traffic_config\": {\n",
    "            \"routes\": [\n",
    "                {\n",
    "                    \"served_model_name\": f\"{uc_model_location.split('.')[-1]}-{max_version}\",\n",
    "                    \"traffic_percentage\": 100\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    create_or_update_func = None\n",
    "    try:\n",
    "        deploy_client.get_endpoint(name)\n",
    "        create_or_update_func = deploy_client.update_endpoint\n",
    "    except HTTPError as e:\n",
    "        if e.response.status_code == 404:\n",
    "            create_or_update_func = deploy_client.create_endpoint\n",
    "        else:\n",
    "            raise\n",
    "    create_or_update_func(name, model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56b18571-8ce0-41e6-9cec-f9ec657e37ba",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "create_or_update_depyloyment(\n",
    "    \"azure_openai_proxy_public\",\n",
    "    api_endpoint=\"https://<endpoint>.openai.azure.com\",\n",
    "    api_key_secret_scope=\"<scope>\",\n",
    "    api_key_secret_key=\"<key>\", \n",
    "    api_version=\"2023-05-15\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Azure OpenAI Proxy",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
